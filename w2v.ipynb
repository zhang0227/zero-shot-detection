{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'air conditioner': '133',\n",
       " 'barrel/bucket': '130',\n",
       " 'bread': '115',\n",
       " 'cabinet/shelf': '132',\n",
       " 'camel': '107',\n",
       " 'canned': '116',\n",
       " 'carriage': '118',\n",
       " 'clutch': '135',\n",
       " 'converter': '121',\n",
       " 'cymbal': '100',\n",
       " 'fish': '106',\n",
       " 'gas stove': '127',\n",
       " 'hat': '136',\n",
       " 'hockey': '105',\n",
       " 'hotair balloon': '119',\n",
       " 'iron': '134',\n",
       " 'lemon': '112',\n",
       " 'life saver': '104',\n",
       " 'luggage': '137',\n",
       " 'meat balls': '117',\n",
       " 'microphone': '122',\n",
       " 'necklace': '138',\n",
       " 'pear': '114',\n",
       " 'pen/pencil': '124',\n",
       " 'pepper': '110',\n",
       " 'piano': '101',\n",
       " 'pigeon': '108',\n",
       " 'printer': '120',\n",
       " 'pumpkin': '111',\n",
       " 'scale': '125',\n",
       " 'soccer': '103',\n",
       " 'stapler': '123',\n",
       " 'stool': '126',\n",
       " 'strawberry': '113',\n",
       " 'tomato': '109',\n",
       " 'toothpaste': '131',\n",
       " 'trophy': '139',\n",
       " 'trumpet': '102',\n",
       " 'vent': '128',\n",
       " 'washing machine': '129'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('clsname2id_20k.json','r') as clsname:\n",
    "    clsnamedict = json.load(clsname)\n",
    "clsnamedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "unseenlist = []\n",
    "idlist = []\n",
    "csvlist = []\n",
    "for name,i in clsnamedict.items():\n",
    "    i = int (i)\n",
    "    unseenlist.append(name)\n",
    "    idlist.append(i)\n",
    "    csvlist.append({'name':name,'id':i})\n",
    "print (len(unseenlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(csvlist).to_csv('unseen_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "4717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4737"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseenlist = []\n",
    "voclist = []\n",
    "\n",
    "for name,i in clsnamedict.items():\n",
    "    unseenlist.append(name)\n",
    "print (len(unseenlist))\n",
    "with open ('vocabulary_list.txt','r') as voc:\n",
    "    for line in voc.readlines():\n",
    "        voclist.append(line.replace('\\n',''))\n",
    "print(len(voclist))\n",
    "vocset = set(voclist)\n",
    "for name in unseenlist:\n",
    "    vocset.add(name)\n",
    "len(vocset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in unseenlist:\n",
    "    if name in voclist:\n",
    "        voclist.remove(name)\n",
    "len(voclist)\n",
    "with open('new_vocabulary_list.txt','w') as f:\n",
    "    for i in voclist:\n",
    "        f.write(i+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4730"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneword_unseen = []\n",
    "voclist = []\n",
    "with open ('oneword_unseen.txt','r') as f:\n",
    "    for i in f.readlines():\n",
    "        i = i.replace('\\n','').replace(' ','')\n",
    "        \n",
    "        oneword_unseen.append(i)\n",
    "with open ('vocabulary_list.txt','r') as voc:\n",
    "    for line in voc.readlines():\n",
    "        voclist.append(line.replace('\\n',''))\n",
    "print(len(voclist))\n",
    "vocset = set(voclist)\n",
    "for name in oneword_unseen:\n",
    "    vocset.add(name)\n",
    "len(vocset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4682"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneword = []\n",
    "voclist = []\n",
    "with open ('oneword.txt','r') as f:\n",
    "    for i in f.readlines():\n",
    "        i = i.replace('\\n','').replace(' ','')\n",
    "        \n",
    "        oneword.append(i)\n",
    "with open ('vocabulary_list.txt','r') as voc:\n",
    "    for line in voc.readlines():\n",
    "        line =line.replace('\\n','')\n",
    "        if line not in oneword:\n",
    "            voclist.append(line)\n",
    "print(len(voclist))\n",
    "vocset = set(voclist)\n",
    "len(vocset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('new_vocabulary_list.txt','w') as f:\n",
    "    for i in voclist:\n",
    "        f.write(i+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 120)\n",
      "(300, 120)\n",
      "(120, 300)\n",
      "(300, 120)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.1518596 ,  0.0539039 ,  0.12685375, ...,  0.0598392 ,\n",
       "        -0.08365142,  0.1414175 ],\n",
       "       [ 0.00627529, -0.08232573,  0.0846593 , ...,  0.02267379,\n",
       "        -0.0012135 ,  0.18508144],\n",
       "       [-0.09384689, -0.03513627, -0.06236986, ..., -0.01098731,\n",
       "        -0.20607427,  0.09409393],\n",
       "       ..., \n",
       "       [ 0.04415767,  0.09259798,  0.12451626, ..., -0.03051862,\n",
       "         0.0515439 , -0.06570275],\n",
       "       [-0.02886305,  0.0780801 ,  0.06545338, ...,  0.07859973,\n",
       "         0.21985051,  0.1111536 ],\n",
       "       [ 0.03711762, -0.08008664,  0.08344582, ..., -0.04560372,\n",
       "        -0.04331677, -0.01695626]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#正则化\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "def normal_w2v(v):\n",
    "    print(v.shape)\n",
    "    v = v.T\n",
    "    print(v.shape)\n",
    "    v = K.l2_normalize(v,axis=0)\n",
    "    v = K.eval(v)\n",
    "    v = v.T\n",
    "    print(v.shape)\n",
    "    return v\n",
    "word = np.loadtxt('all_word_glo.txt',dtype='float32', delimiter=',')\n",
    "print(word.shape)\n",
    "normal_w2v(word)\n",
    "#np.savetxt('all_word_glo_l2.txt',normal_w2v(word),fmt=\"%.6f\", delimiter=',')\n",
    "#voca = np.loadtxt('new_vocabulary_glo.txt',dtype='float32', delimiter=',')\n",
    "#np.savetxt('new_vocabulary_glo_l2.txt',normal_w2v(voca), fmt=\"%.6f\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
